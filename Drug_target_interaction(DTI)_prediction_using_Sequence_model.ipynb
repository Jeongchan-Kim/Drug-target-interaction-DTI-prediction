{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeongchan-Kim/Drug-target-interaction-DTI-prediction/blob/main/Drug_target_interaction(DTI)_prediction_using_Sequence_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x4FvEuY9msK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEsyWIdpNDHk"
      },
      "source": [
        "### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wut5lPnjJN1D"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7t0Pk7xGprJ"
      },
      "outputs": [],
      "source": [
        "# 공유 폴더에 저장된 데이터 현재 폴더에 압축풀기\n",
        "\n",
        "!unzip /content/drive/MyDrive/test1/DAVIS.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWG612C8Gthu"
      },
      "outputs": [],
      "source": [
        "# drug - target binding affinity 데이터\n",
        "affinity = pd.read_csv('/content/DAVIS/affinity.txt', header=None, sep = ' ')\n",
        "\n",
        "# Target protein sequence 데이터\n",
        "with open('/content/DAVIS/target_seq.txt') as f:\n",
        "    target = json.load(f)\n",
        "    target = list(target.values())\n",
        "\n",
        "# Drug SMILES 데이터\n",
        "with open('/content/DAVIS/SMILES.txt') as f:\n",
        "    drug = json.load(f)\n",
        "    drug = list(drug.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVu2IZopNGrl"
      },
      "source": [
        "### 데이터 탐색 (Exploratory data analysis) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiiSr6FNYNY"
      },
      "source": [
        "**Binding Affiniry**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4BWw2oGNvXm"
      },
      "outputs": [],
      "source": [
        "affinity.shape\n",
        "\n",
        "# 행(row): drugs\n",
        "# 열(col): target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0HVIOoqM87I"
      },
      "outputs": [],
      "source": [
        "affinity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwHT19FlOFkS"
      },
      "outputs": [],
      "source": [
        "affinity.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8gGMTRiOrJR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue-rSXaPOrpm"
      },
      "source": [
        "**Target protein & Drug**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0mbaRoNOy1a"
      },
      "outputs": [],
      "source": [
        "print(f\"총 protein 개수: {len(target)}\")\n",
        "print(f\"총 drug 개수: {len(drug)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aTePlZEOtIs"
      },
      "outputs": [],
      "source": [
        "print(\"Target protein sequence 예시: \")\n",
        "print(target[0])\n",
        "print(\"Drug SMILES 예시: \")\n",
        "print(drug[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiYVTKRJO5nP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDy11ttrPMTt"
      },
      "source": [
        "### 데이터 전처리 (Data pre-processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--PLWkkITRLa"
      },
      "source": [
        "**데이터 프레임 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ_eU3VIRaJC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD9XOSVlJBxU"
      },
      "outputs": [],
      "source": [
        "# SMILES - Target - Affinity paired list 만들기\n",
        "\n",
        "SMILES = [] \n",
        "Target_seq = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(drug)):\n",
        "  for j in range(len(target)):\n",
        "    SMILES.append(drug[i])\n",
        "    Target_seq.append(target[j])\n",
        "    y.append(affinity.values[i, j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0t3wfhWLaI1"
      },
      "outputs": [],
      "source": [
        "# Binding affinity cutoff로 affinity 이진화(binary)하기\n",
        "\n",
        "threshold = 300 # Binding affinity cutoff\n",
        "\n",
        "y = [1 if i else 0 for i in np.array(y) < threshold]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE9R8809MugI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0iPES4fOlGK"
      },
      "outputs": [],
      "source": [
        "# 모든 데이터 하나의 데이터 프레임으로 만들기\n",
        "\n",
        "All_Data_dictionary = {\"SMILES\": SMILES,\n",
        "                        \"Target Sequence\": Target_seq,\n",
        "                        \"Label\":y}\n",
        "\n",
        "df_data = pd.DataFrame(All_Data_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PmLyeR1Muq1"
      },
      "outputs": [],
      "source": [
        "df_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsCihZx4QUHg"
      },
      "outputs": [],
      "source": [
        "print(f'전체 drug-target pair 수: {str(len(df_data))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3F_UBiRqFsE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYPCLKQlpybY"
      },
      "outputs": [],
      "source": [
        "# Label 비율 확인\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = df_data['Label'].value_counts() # label counts\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0,1]) \n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.barplot(x, counts)\n",
        "ax.set_xticks(x)\n",
        "\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Counts\")"
      ],
      "metadata": {
        "id": "ipbqOP0jpR9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qccQI9UMTWIj"
      },
      "source": [
        "**학습에 사용할 수 있도록 데이터 정제**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5xE87QCQUJ9"
      },
      "outputs": [],
      "source": [
        "### 데이터 정제를 위한 설정 \n",
        "\n",
        "# 아미노산 charater 정의\n",
        "amino_char = ['?', 'A', 'C', 'B', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'O',\n",
        "       'N', 'Q', 'P', 'S', 'R', 'U', 'T', 'W', 'V', 'Y', 'X', 'Z']\n",
        "\n",
        "# SMILES character 정의\n",
        "smiles_char = ['?', '#', '%', ')', '(', '+', '-', '.', '1', '0', '3', '2', '5', '4',\n",
        "       '7', '6', '9', '8', '=', 'A', 'C', 'B', 'E', 'D', 'G', 'F', 'I',\n",
        "       'H', 'K', 'M', 'L', 'O', 'N', 'P', 'S', 'R', 'U', 'T', 'W', 'V',\n",
        "       'Y', '[', 'Z', ']', '_', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i',\n",
        "       'h', 'm', 'l', 'o', 'n', 's', 'r', 'u', 't', 'y']\n",
        "\n",
        "# protein, drug 원핫(one-hot) 인코더\n",
        "enc_protein = OneHotEncoder().fit(np.array(amino_char).reshape(-1, 1))\n",
        "enc_drug = OneHotEncoder().fit(np.array(smiles_char).reshape(-1, 1))\n",
        "\n",
        "# Protein 최대 길이\n",
        "MAX_SEQ_PROTEIN = 1000\n",
        "\n",
        "# Drug 최대 길이\n",
        "MAX_SEQ_DRUG = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEOG1arpQUMJ"
      },
      "outputs": [],
      "source": [
        "def trans_drug(x):\n",
        "\t\"\"\"SMILES 데이터 전처리하기\n",
        "\n",
        "\t같은 크기(MAX_SEQ_DRUG)의 리스트로 만들기\n",
        "\t사전 정의된 character에 해당 되지 않는 값은 ?로 변환\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: 하나의 SMILES 데이터 (string)\n",
        "\t\n",
        "\tReturn:\n",
        "\t\t전처리된 SMILES 데이터 리스트\n",
        "\t\"\"\"\n",
        "\n",
        "\ttemp = list(x) # str -> list\n",
        "\ttemp = [i if i in smiles_char else '?' for i in temp] # 사전 정의된 character에 없으면 ?로 변환\n",
        "\n",
        "\tif len(temp) < MAX_SEQ_DRUG: \n",
        "\t\t# MAX_SEQ_DRUG 보다 작으면 뒷부분을 ?로 채워서 MAX_SEQ_DRUG 길이의 리스트로 만들기\n",
        "\t\ttemp = temp + ['?'] * (MAX_SEQ_DRUG-len(temp))\n",
        "\telse:\n",
        "\t\t# MAX_SEQ_DRUG 보다 크면 앞에서부터 MAX_SEQ_DRUG 만큼 슬라이싱\n",
        "\t\ttemp = temp[:MAX_SEQ_DRUG]\n",
        "\n",
        "\treturn temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvu9_YGqQUON"
      },
      "outputs": [],
      "source": [
        "def trans_protein(x):\n",
        "\t\"\"\"Protein sequence 데이터 전처리하기\n",
        "\n",
        "\t같은 크기(MAX_SEQ_PROTEIN)의 리스트로 만들기\n",
        "\t사전 정의된 character에 해당 되지 않는 값은 ?로 변환\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: 하나의 sequence 데이터 (string)\n",
        "\t\n",
        "\tReturn:\n",
        "\t\t전처리된 SMILES 데이터 리스트\n",
        "\t\"\"\"\n",
        "\n",
        "\ttemp = list(x.upper()) # 대문자로 바꾸기\n",
        "\ttemp = [i if i in amino_char else '?' for i in temp] # \n",
        "\n",
        "\tif len(temp) < MAX_SEQ_PROTEIN:\n",
        "\t\t# MAX_SEQ_PROTEIN 보다 작으면 뒷부분을 ?로 채워서 MAX_SEQ_DRUG 길이의 리스트로 만들기\n",
        "\t\ttemp = temp + ['?'] * (MAX_SEQ_PROTEIN-len(temp))\n",
        "\telse:\n",
        "\t\t# MAX_SEQ_PROTEIN 보다 크면 앞에서부터 MAX_SEQ_DRUG 만큼 슬라이싱\n",
        "\t\ttemp = temp [:MAX_SEQ_PROTEIN]\n",
        "\n",
        "\treturn temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx-y1iceQUQM"
      },
      "outputs": [],
      "source": [
        "# Drug 데이터 중 중복되지 않는 것만 processing\n",
        "unique_drug = pd.Series(df_data[\"SMILES\"].unique()).apply(trans_drug)\n",
        "\n",
        "# raw SMILES - processed SMILES 딕셔너리 \n",
        "unique_dict = dict(zip(df_data[\"SMILES\"].unique(), unique_drug))\n",
        "\n",
        "# 전체 데이터 processing\n",
        "df_data[\"drug_encoding\"] = [unique_dict[i] for i in df_data[\"SMILES\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k414eVC1QUSM"
      },
      "outputs": [],
      "source": [
        "# Protein 데이터 중 중복되지 않는 것만 processing\n",
        "AA = pd.Series(df_data[\"Target Sequence\"].unique()).apply(trans_protein)\n",
        "\n",
        "# raw protein - processed protein 딕셔너리 \n",
        "AA_dict = dict(zip(df_data[\"Target Sequence\"].unique(), AA))\n",
        "\n",
        "# 전체 데이터 processing\n",
        "df_data[\"target_encoding\"] = [AA_dict[i] for i in df_data[\"Target Sequence\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlNHO79sQUUM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0qSxxQYY3Wb"
      },
      "source": [
        "**데이터 나누기 (Train / Validation / Test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G_QG70TQUWT"
      },
      "outputs": [],
      "source": [
        "def create_fold(df, fold_seed, frac):\n",
        "    \"\"\"Train / Val / Test 나누기\n",
        "\n",
        "    Args:\n",
        "        df: 전체 데이터 (Pandas DataFrame)\n",
        "        fold_seed: random_state for random sampling\n",
        "        frac: train - val - test fraction (list or tuple) ex) [0.7,0.1,0.2]\n",
        "    \n",
        "    Returns:\n",
        "        Train / Val / Test dataframe (tuple)\n",
        "    \"\"\"\n",
        "    train_frac, val_frac, test_frac = frac \n",
        "\n",
        "    # Test 데이터 random sampling\n",
        "    test = df.sample(frac = test_frac, replace = False, random_state = fold_seed)\n",
        "    train_val = df[~df.index.isin(test.index)] # Train & Validation 데이터 \n",
        "\n",
        "    # Validation 데이터 random sampling\n",
        "    val = train_val.sample(frac = val_frac/(1-test_frac), replace = False, random_state = 1)\n",
        "    train = train_val[~train_val.index.isin(val.index)] # Train 데이터\n",
        "    \n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzQO9rodQUYV"
      },
      "outputs": [],
      "source": [
        "train, val, test = create_fold(df_data, 22, [0.7,0.1,0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teuKQCvJQUad"
      },
      "outputs": [],
      "source": [
        "# 잘 나누어졌는지 확인\n",
        "\n",
        "print(f'Train 데이터 크기: {len(train)}')\n",
        "print(f'Validation 데이터 크기: {len(val)}')\n",
        "print(f'Test 데이터 크기: {len(test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrWMK7EhL-pv"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvLusMviTtHt"
      },
      "outputs": [],
      "source": [
        "val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnYLUlLBTtKB"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_oOkW9MTtMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilL_QytUdDLi"
      },
      "source": [
        "**Drug & Protein encoding 함수**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGQgIr18MEyx"
      },
      "outputs": [],
      "source": [
        "# Drug one-hot 인코딩\n",
        "\n",
        "def drug_2_embed(x):\n",
        "\treturn enc_drug.transform(np.array(x).reshape(-1,1)).toarray().T    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIkbzgakMUBQ"
      },
      "outputs": [],
      "source": [
        "# Protein one-hot 인코딩\n",
        "\n",
        "def protein_2_embed(x):\n",
        "\treturn enc_protein.transform(np.array(x).reshape(-1,1)).toarray().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeiaiONcdJUd"
      },
      "source": [
        "# 학습을 위한 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyVHmYqehN3"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7OjQSQSMX9k"
      },
      "outputs": [],
      "source": [
        "# 필요한 library 불러오기\n",
        "\n",
        "import torch\n",
        "from torch import nn \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9yK4xD3MZka"
      },
      "outputs": [],
      "source": [
        "# 디바이스 설정\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"현재 디바이스는 {device} 입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POA3FqhmMeIF"
      },
      "outputs": [],
      "source": [
        "# Custom dataset 만들기 \n",
        "\n",
        "class data_process_loader(Dataset):\n",
        "    def __init__(self, df):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df: Paired drug - protein - affinity dataframe\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"샘플 개수\n",
        "        \"\"\"\n",
        "        return self.df.shape[0] \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Drug 데이터\n",
        "        v_d = self.df.iloc[index]['drug_encoding'] \n",
        "        v_d = drug_2_embed(v_d) # Drug One-hot 인코딩 [63,100]\n",
        "\n",
        "        # Target 데이터\n",
        "        v_p = self.df.iloc[index]['target_encoding'] \n",
        "        v_p = protein_2_embed(v_p) # Target One-hot 인코딩 [26,100]\n",
        "\n",
        "        # Binding affinity (label)\n",
        "        y = self.df.iloc[index]['Label'] \n",
        "\n",
        "        return v_d, v_p, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKmNQ842MeMQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = data_process_loader(train)\n",
        "valid_dataset = data_process_loader(val)\n",
        "test_dataset = data_process_loader(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCen6cNeMeOk"
      },
      "outputs": [],
      "source": [
        "# Dataset 확인 해보기 \n",
        "\n",
        "for (v_d, v_p, y) in valid_dataset:\n",
        "    print(v_d.shape)\n",
        "    print(v_p.shape)\n",
        "    print(y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heUn3CsgMeQX"
      },
      "outputs": [],
      "source": [
        "# DataLoader 파라미터\n",
        "\n",
        "params = {'batch_size': 256,\n",
        "            'shuffle': True,\n",
        "            'num_workers': 1,\n",
        "            'drop_last': False}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xucsijxtNE98"
      },
      "outputs": [],
      "source": [
        "# Mini-batch 학습을 위한 DataLoader\n",
        "\n",
        "training_generator = DataLoader(train_dataset, **params)\n",
        "valid_generator = DataLoader(valid_dataset, **params)\n",
        "test_generator = DataLoader(test_dataset, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjdhbQGqNF4c"
      },
      "outputs": [],
      "source": [
        "# Dataloader 확인해보기 \n",
        "\n",
        "for (v_d, v_p, y) in training_generator:\n",
        "    print(v_d.shape)\n",
        "    print(v_p.shape)\n",
        "    print(y)\n",
        "\n",
        "    drug_demo = v_d\n",
        "    protein_demo = v_p\n",
        "    affinity_demo = y\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuQ743Lq0yxF"
      },
      "outputs": [],
      "source": [
        "for (v_d, v_p, y) in valid_generator:\n",
        "    print(v_d.shape)\n",
        "    print(v_p.shape)\n",
        "    print(y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27iMVQbn0xaS"
      },
      "outputs": [],
      "source": [
        "for (v_d, v_p, y) in test_generator:\n",
        "    print(v_d.shape)\n",
        "    print(v_p.shape)\n",
        "    print(y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB_UMNEueK9s"
      },
      "source": [
        "### Binding affinity 예측 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFQziTb8NJZP"
      },
      "outputs": [],
      "source": [
        "### Drug data\n",
        "\n",
        "# input data \n",
        "inp = drug_demo.double()\n",
        "print(f\"Input: {list(inp.shape)}\") \n",
        "\n",
        "# 1D convolution 적용하기\n",
        "conv1 = nn.Conv1d(in_channels = 63, out_channels = 32, kernel_size = 4).double()\n",
        "drug_after_conv1 = F.relu(conv1(inp))\n",
        "print(f\"Conv1: {list(drug_after_conv1.shape)}\") \n",
        "\n",
        "conv2 = nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 6).double()\n",
        "drug_after_conv2 = F.relu(conv2(drug_after_conv1))\n",
        "print(f\"Conv2: {list(drug_after_conv2.shape)}\") \n",
        "\n",
        "conv3 = nn.Conv1d(in_channels = 64, out_channels = 96, kernel_size = 8).double()\n",
        "drug_after_conv3 = F.relu(conv3(drug_after_conv2))\n",
        "print(f\"Conv3: {list(drug_after_conv3.shape)}\") \n",
        "\n",
        "# # max pooling\n",
        "# pooled = F.adaptive_max_pool1d(drug_after_conv3, output_size=1)\n",
        "# print(f\"Pooled: {list(pooled.shape)}\") \n",
        "\n",
        "# # Linear embedding\n",
        "# fc = nn.Linear(96, 256)\n",
        "# pooled = pooled.view(pooled.size(0), -1) # [256, 96, 1] -> [256, 96]\n",
        "# final = fc(pooled.float())\n",
        "# print(f\"Final: {list(final.shape)}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppuCinGxr-Yp"
      },
      "source": [
        "**RNN demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-6sNgchNKZL"
      },
      "outputs": [],
      "source": [
        "### Drug data\n",
        "\n",
        "rnn_drug_n_layers = 2\n",
        "rnn_drug_hid_dim = 64\n",
        "hidden_dim_drug = 256\n",
        "\n",
        "rnn = nn.GRU(input_size = 96, # input feature 사이즈 (마지막 convolution 이 후 채널 개수)\n",
        "            hidden_size = rnn_drug_hid_dim, # hidden feature 사이즈\n",
        "            num_layers = rnn_drug_n_layers, # recurrent layer 개수\n",
        "            batch_first = True, # If True, (batch, seq, feature) Else, (seq, batch, feature)\n",
        "            bidirectional = True) # If True, Bidirectional LSTM\n",
        "            \n",
        "rnn = rnn.double()\n",
        "\n",
        "emb = drug_after_conv3\n",
        "\n",
        "batch_size = emb.size(0)\n",
        "emb = emb.view(batch_size, emb.size(2), -1) \n",
        "print(f\"RNN 입력값: {list(emb.shape)}\") \n",
        "# [256, 96, 85] -> [256, 85, 96]\n",
        "\n",
        "# GRU\n",
        "direction = 2 \n",
        "\n",
        "h0 = torch.randn(rnn_drug_n_layers * direction, batch_size, rnn_drug_hid_dim).double() # Initialize hidden state \n",
        "print(f\"hidden state: {list(h0.shape)}\") # hidden state\n",
        "v, hn = rnn(emb, h0) \n",
        "\n",
        "print(f\"RNN 출력값: {list(v.shape)}\") \n",
        "\n",
        "# Linear embedding\n",
        "fc1 = nn.Linear(rnn_drug_hid_dim * direction * 85, hidden_dim_drug)\n",
        "v = torch.flatten(v, 1)\n",
        "v = fc1(v.float())\n",
        "print(f\"최종 임베딩 후 사이즈: {list(v.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdYilUOIsF9_"
      },
      "source": [
        "**모델 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMrKLVEeNMyc"
      },
      "outputs": [],
      "source": [
        "# 모델 설정 값\n",
        "\n",
        "config = {\n",
        "    # drug 설정\n",
        "    \"cnn_drug_filters\" : [32,64,96],\n",
        "    \"cnn_drug_kernels\" : [4,6,8],\n",
        "    \"hidden_dim_drug\" : 256,\n",
        "    \"rnn_drug_hid_dim\" : 64,\n",
        "    \"rnn_drug_n_layers\" : 2,\n",
        "    \"rnn_drug_bidirectional\" : True,\n",
        "    \"rnn_Use_GRU_LSTM_target\" : 'GRU',\n",
        "\n",
        "    # protein 설정\n",
        "    \"cnn_target_filters\" : [32,64,96],\n",
        "    \"cnn_target_kernels\" : [4,8,12],\n",
        "    \"hidden_dim_protein\" : 256,\n",
        "    \"rnn_target_hid_dim\" : 64,\n",
        "    \"rnn_target_n_layers\" : 2,\n",
        "    \"rnn_target_bidirectional\" : True,\n",
        "    \"rnn_Use_GRU_LSTM_drug\" : 'GRU',\n",
        "\n",
        "    # Classfier 설정\n",
        "    \"cls_hidden_dims\" : [1024, 1024, 512]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx7KwqJGtvD3"
      },
      "outputs": [],
      "source": [
        "# CNN - RNN 모델 \n",
        "\n",
        "class CNN_RNN(nn.Sequential):\n",
        "\t\"\"\"CNN과 RNN을 이용하여 특성 추출(feature extration)\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, encoding, **config):\n",
        "\t\tsuper(CNN_RNN, self).__init__()\n",
        "  \n",
        "\t\tif encoding == 'drug':\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tCNN 구현 \n",
        "\t\t\t\"\"\"\n",
        "\t\t\t# 레이어 별 CNN 필터 개수 \n",
        "\t\t\tin_ch = [63] + config['cnn_drug_filters']\n",
        "\t\t\tself.in_ch = in_ch[-1] # 마지막 convolution 층 필터 개수\n",
        "\n",
        "\t\t\t# 레이어 별 CNN kernel 사이즈\n",
        "\t\t\tkernels = config['cnn_drug_kernels']\n",
        "\n",
        "\t\t\t# 전체 CNN Layer 개수\n",
        "\t\t\tlayer_size = len(config['cnn_drug_filters'])\n",
        "   \n",
        "\t\t\tself.conv = nn.ModuleList([nn.Conv1d(in_channels = in_ch[i], # input 채널 수\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tout_channels = in_ch[i+1], # output 채널 수\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tkernel_size = kernels[i]) for i in range(layer_size)]) # kernel 사이즈\n",
        "\t\t\tself.conv = self.conv.double()\n",
        "\n",
        "\t\t\t# 마지막 층 사이즈 구하기\n",
        "\t\t\tn_size_d = self._get_conv_output((63, 100)) # auto get the seq_len of CNN output\n",
        "\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tRNN 구현 (LSTM / GRU)\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tif config['rnn_Use_GRU_LSTM_drug'] == 'LSTM':\n",
        "\t\t\t\tself.rnn = nn.LSTM(input_size = in_ch[-1], # input feature 사이즈 (convolution 이 후 채널 개수)\n",
        "\t\t\t\t\t\t\t\thidden_size = config['rnn_drug_hid_dim'], # hidden feature 사이즈\n",
        "\t\t\t\t\t\t\t\tnum_layers = config['rnn_drug_n_layers'], # recurrent layer 개수\n",
        "\t\t\t\t\t\t\t\tbatch_first = True, # If True, (batch, seq, feature) Else, (seq, batch, feature)\n",
        "\t\t\t\t\t\t\t\tbidirectional = config['rnn_drug_bidirectional']) # If True, Bidirectional LSTM\n",
        "\t\t\t\n",
        "\t\t\telif config['rnn_Use_GRU_LSTM_drug'] == 'GRU':\n",
        "\t\t\t\tself.rnn = nn.GRU(input_size = in_ch[-1], # input feature 사이즈 (convolution 이 후 채널 개수)\n",
        "\t\t\t\t\t\t\t\thidden_size = config['rnn_drug_hid_dim'], # hidden feature 사이즈\n",
        "\t\t\t\t\t\t\t\tnum_layers = config['rnn_drug_n_layers'], # recurrent layer 개수\n",
        "\t\t\t\t\t\t\t\tbatch_first = True, # If True, (batch, seq, feature) Else, (seq, batch, feature\n",
        "\t\t\t\t\t\t\t\tbidirectional = config['rnn_drug_bidirectional']) # If True, Bidirectional LSTM\n",
        "\t\t\telse:\n",
        "\t\t\t\traise AttributeError('Please use LSTM or GRU.')\n",
        "\n",
        "\t\t\tdirection = 2 if config['rnn_drug_bidirectional'] else 1\n",
        "\t\t\tself.rnn = self.rnn.double()\n",
        "   \n",
        "\t\t\t# 마지막 drug 임베딩 층\n",
        "\t\t\tself.fc1 = nn.Linear(config['rnn_drug_hid_dim'] * direction * n_size_d, config['hidden_dim_drug'])\n",
        "\n",
        "\t\tif encoding == 'protein':\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tCNN 구현 \n",
        "\t\t\t\"\"\"\n",
        "\t\t\t# 레이어 별 CNN 필터 개수 \n",
        "\t\t\tin_ch = [26] + config['cnn_target_filters']\n",
        "\t\t\tself.in_ch = in_ch[-1]\n",
        "\n",
        "\t\t\t# 레이어 별 CNN kernel 사이즈\n",
        "\t\t\tkernels = config['cnn_target_kernels']\n",
        "\n",
        "\t\t\t# 전체 CNN Layer 개수\n",
        "\t\t\tlayer_size = len(config['cnn_target_filters'])\n",
        "\n",
        "\t\t\tself.conv = nn.ModuleList([nn.Conv1d(in_channels = in_ch[i], # input 채널 수\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tout_channels = in_ch[i+1], # output 채널 수\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tkernel_size = kernels[i]) for i in range(layer_size)]) # kernel 사이즈\n",
        "\t\t\tself.conv = self.conv.double()\n",
        "   \n",
        "\t\t\t# 마지막 층 사이즈 구하기\n",
        "\t\t\tn_size_p = self._get_conv_output((26, 1000))\n",
        "   \n",
        "\t\t\t\"\"\"\n",
        "\t\t\tRNN 구현 (LSTM / GRU)\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tif config['rnn_Use_GRU_LSTM_target'] == 'LSTM':\n",
        "\t\t\t\tself.rnn = nn.LSTM(input_size = in_ch[-1], # input feature 사이즈 (convolution 이 후 채널 개수)\n",
        "\t\t\t\t\t\t\t\thidden_size = config['rnn_target_hid_dim'], # hidden feature 사이즈\n",
        "\t\t\t\t\t\t\t\tnum_layers = config['rnn_target_n_layers'], # recurrent layer 개수\n",
        "\t\t\t\t\t\t\t\tbatch_first = True, # If True, (batch, seq, feature) Else, (seq, batch, feature)\n",
        "\t\t\t\t\t\t\t\tbidirectional = config['rnn_target_bidirectional']) # If True, Bidirectional LSTM\n",
        "\n",
        "\t\t\telif config['rnn_Use_GRU_LSTM_target'] == 'GRU':\n",
        "\t\t\t\tself.rnn = nn.GRU(input_size = in_ch[-1], \n",
        "\t\t\t\t\t\t\t\thidden_size = config['rnn_target_hid_dim'],\n",
        "\t\t\t\t\t\t\t\tnum_layers = config['rnn_target_n_layers'],\n",
        "\t\t\t\t\t\t\t\tbatch_first = True,\n",
        "\t\t\t\t\t\t\t\tbidirectional = config['rnn_target_bidirectional'])\n",
        "\t\t\telse:\n",
        "\t\t\t\traise AttributeError('Please use LSTM or GRU.')\n",
        "\n",
        "\t\t\tdirection = 2 if config['rnn_target_bidirectional'] else 1\n",
        "\t\t\tself.rnn = self.rnn.double()\n",
        "   \n",
        "\t\t\t# 마지막 protein 임베딩 층\n",
        "\t\t\tself.fc1 = nn.Linear(config['rnn_target_hid_dim'] * direction * n_size_p, config['hidden_dim_protein'])\n",
        "   \n",
        "\t\tself.encoding = encoding\n",
        "\t\tself.config = config\n",
        "\n",
        "\tdef _get_conv_output(self, shape):\n",
        "\t\t\"\"\"마지막 \n",
        "\t\t\"\"\"\n",
        "\t\tbs = 1\n",
        "\t\tinput = Variable(torch.rand(bs, *shape))\n",
        "\t\toutput_feat = self._forward_features(input.double())\n",
        "\t\tn_size = output_feat.data.view(bs, self.in_ch, -1).size(2)\n",
        "\t\treturn n_size\n",
        "\n",
        "\tdef _forward_features(self, x):\n",
        "\t\tfor l in self.conv:\n",
        "\t\t\tx = F.relu(l(x))\n",
        "\t\treturn x\n",
        "\n",
        "\tdef forward(self, v):\n",
        "\t\tv = self._forward_features(v.double())\n",
        "  \n",
        "\t\tbatch_size = v.size(0)\n",
        "\t\tv = v.view(batch_size, v.size(2), -1) \n",
        "  \t\t# drug: [256, 96, 85] -> [256, 85, 96]\n",
        "\t\t# protein: [256, 96, 979] -> [256, 979, 96]\n",
        "\n",
        "\t\tif self.encoding == 'protein':\n",
        "\t\t\tif self.config['rnn_Use_GRU_LSTM_target'] == 'LSTM':\n",
        "\t\t\t\tdirection = 2 if self.config['rnn_target_bidirectional'] else 1\n",
        "\t\t\t\th0 = torch.randn(self.config['rnn_target_n_layers'] * direction, batch_size, self.config['rnn_target_hid_dim']).to(device) # Initialize hidden state\n",
        "\t\t\t\tc0 = torch.randn(self.config['rnn_target_n_layers'] * direction, batch_size, self.config['rnn_target_hid_dim']).to(device) # Initialize cell state\n",
        "\t\t\t\tv, (hn, cn) = self.rnn(v.double(), (h0.double(), c0.double()))\n",
        "\t\t\telse:\n",
        "\t\t\t\t# GRU\n",
        "\t\t\t\tdirection = 2 if self.config['rnn_target_bidirectional'] else 1\n",
        "\t\t\t\th0 = torch.randn(self.config['rnn_target_n_layers'] * direction, batch_size, self.config['rnn_target_hid_dim']).to(device)\n",
        "\t\t\t\tv, hn = self.rnn(v.double(), h0.double())\n",
        "\t\telse:\n",
        "\t\t\tif self.config['rnn_Use_GRU_LSTM_drug'] == 'LSTM':\n",
        "\t\t\t\tdirection = 2 if self.config['rnn_drug_bidirectional'] else 1\n",
        "\t\t\t\th0 = torch.randn(self.config['rnn_drug_n_layers'] * direction, batch_size, self.config['rnn_drug_hid_dim']).to(device) # Initialize hidden state\n",
        "\t\t\t\tc0 = torch.randn(self.config['rnn_drug_n_layers'] * direction, batch_size, self.config['rnn_drug_hid_dim']).to(device) # Initialize cell state\n",
        "\t\t\t\tv, (hn, cn) = self.rnn(v.double(), (h0.double(), c0.double()))\n",
        "\t\t\telse:\n",
        "\t\t\t\t# GRU\n",
        "\t\t\t\tdirection = 2 if self.config['rnn_drug_bidirectional'] else 1\n",
        "\t\t\t\th0 = torch.randn(self.config['rnn_drug_n_layers'] * direction, batch_size, self.config['rnn_drug_hid_dim']).to(device)\n",
        "\t\t\t\tv, hn = self.rnn(v.double(), h0.double())\n",
        "\t\t\t\t\n",
        "\t\tv = torch.flatten(v, 1)\n",
        "\t\tv = self.fc1(v.float())\n",
        "\t\treturn v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg5pfoq1NRhX"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Sequential):\n",
        "\t\"\"\"\n",
        "\t임베딩 된 drug와 protein을 이용하여 classificaion\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, model_drug, model_protein, **config):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tmodel_drug: drug emedding 모델\n",
        "\t\t\tmodel_protein: protein emedding 모델\n",
        "\t\t\tconfig: 모델 설정 값\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Classifier, self).__init__()\n",
        "\n",
        "\t\tself.input_dim_drug = config['hidden_dim_drug'] # drug feature 사이즈\n",
        "\t\tself.input_dim_protein = config['hidden_dim_protein'] # protein feature 사이즈\n",
        "\n",
        "\t\tself.model_drug = model_drug # drug 임베딩 모델\n",
        "\t\tself.model_protein = model_protein # protein 임베딩 모델\n",
        "\n",
        "\t\tself.dropout = nn.Dropout(0.1) # dropout 적용\n",
        "\n",
        "\t\tself.hidden_dims = config['cls_hidden_dims'] # classifier hidden dimensions\n",
        "\t\tlayer_size = len(self.hidden_dims) + 1 # hidden layer 개수\n",
        "\t\tdims = [self.input_dim_drug + self.input_dim_protein] + self.hidden_dims + [1] # [\"합쳐진 feature 차원 (drug + protein), hidden1, hidden2, hidden3, 1 (output layer)] \n",
        "\t\t\n",
        "\t\tself.predictor = nn.ModuleList([nn.Linear(dims[i], dims[i+1]) for i in range(layer_size)]) # classifer layers \n",
        "\n",
        "\tdef forward(self, v_D, v_P):\n",
        "\t\t# Drug/protein 임베딩\n",
        "\t\tv_D = self.model_drug(v_D)\n",
        "\t\tv_P = self.model_protein(v_P)\n",
        "  \n",
        "\t\t# drug - protein feature 합치기 \n",
        "\t\tv_f = torch.cat((v_D, v_P), 1)\n",
        "  \n",
        "\t\tfor i, l in enumerate(self.predictor):\n",
        "\t\t\tif i == (len(self.predictor)-1):\n",
        "\t\t\t\t# If last layer,\n",
        "\t\t\t\tv_f = l(v_f)\n",
        "\t\t\telse:\n",
        "\t\t\t\t# If Not last layer, dropout과 ReLU 적용\n",
        "\t\t\t\tv_f = F.relu(self.dropout(l(v_f)))\n",
        "\t\n",
        "\t\treturn v_f\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AQcDPJXNPBS"
      },
      "outputs": [],
      "source": [
        "# model for drug\n",
        "model_drug = CNN_RNN('drug', **config)\n",
        "\n",
        "# model for protein\n",
        "model_protein = CNN_RNN('protein', **config)\n",
        "\n",
        "# classifier\n",
        "model = Classifier(model_drug, model_protein, **config)\n",
        "\n",
        "model = model.to(device) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IY8J-WzNQkT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeVq4wo-NSz1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRmYofpEvico"
      },
      "source": [
        "# 모델 학습 (Training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJSsj_oHvgGc"
      },
      "source": [
        "### 학습 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEe5xe1HwZlG"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from prettytable import PrettyTable\n",
        "from time import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, average_precision_score, f1_score, log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhJzFfWaNUK_"
      },
      "outputs": [],
      "source": [
        "# 하이퍼 파라미터(hyper parameter)\n",
        "\n",
        "learning_rate = 0.001\n",
        "weight_decay  = 0.00001\n",
        "train_epoch   = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAEbDETGv6KI"
      },
      "outputs": [],
      "source": [
        "# 옵티마이저 선언\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay) # Adam optimizer\n",
        "\n",
        "# 손실 함수 선언\n",
        "loss_fct = torch.nn.BCELoss()\n",
        "\n",
        "# 시그모이드(sigmoid) 함수\n",
        "sigmoid = torch.nn.Sigmoid() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIh-sHFa1Cq-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQHasA_s1DMI"
      },
      "source": [
        "### 모델 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztop9UVfXjxq"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_label, y_pred):\n",
        "    # metrics\n",
        "    auc = roc_auc_score(y_label, y_pred) # AUC \n",
        "    auprc = average_precision_score(y_label, y_pred) # Average Precision\n",
        "    f1 = f1_score(y_label, outputs) # F1 score\n",
        "    lloss = log_loss(y_label, outputs) # cross-entropy loss \n",
        "\n",
        "    return auc, auprc, f1, lloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEk42F_RwAx6"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss_history = [] \n",
        "\n",
        "max_auc = 0 # 최고 AUC 저장\n",
        "model_max = copy.deepcopy(model) # 최고 AUC 저장\n",
        "\n",
        "valid_metric_record = [] # 각 metrics 저장\n",
        "valid_metric_header = [\"# epoch\"] \n",
        "valid_metric_header.extend([\"AUROC\", \"AUPRC\", \"F1\"])\n",
        "\n",
        "table = PrettyTable(valid_metric_header)\n",
        "\n",
        "float2str = lambda x:'%0.4f'%x  # float 자료 형 str로 만들기 (소숫점 4자리까지)\n",
        "\n",
        "print('--- Go for Training ---')\n",
        "t_start = time() \n",
        "\n",
        "\n",
        "for epoch in range(train_epoch):\n",
        "    # Training\n",
        "    model.train() \n",
        "\n",
        "    for i, (v_d, v_p, label) in enumerate(training_generator):\n",
        "        v_p = v_p.float().to(device) \n",
        "        v_d = v_d.float().to(device) \n",
        "        \n",
        "        # 순전파 (forward-pass)\n",
        "        score = model(v_d, v_p)\n",
        "        label = Variable(torch.from_numpy(np.array(label)).float()).to(device) # label numpy -> torch tensor\n",
        "        \n",
        "        # 모델 아웃풋 score -> probability\n",
        "        n = torch.squeeze(sigmoid(score), 1)\n",
        "        \n",
        "        # 손실 값(loss) 계산\n",
        "        loss = loss_fct(n, label)            \n",
        "        loss_history.append(loss.item()) # loss 기록\n",
        "\n",
        "        opt.zero_grad() # gradient 초기화\n",
        "        loss.backward() # back propagation\n",
        "        opt.step() # parameter 업데이트\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "        y_pred = []\n",
        "        y_label = []\n",
        "\n",
        "        for i, (v_d, v_p, label) in enumerate(valid_generator):\n",
        "            v_p = v_p.float().to(device) \n",
        "            v_d = v_d.float().to(device) \n",
        "\n",
        "            # 순전파 (forward-pass)\n",
        "            score = model(v_d, v_p)\n",
        "            \n",
        "            logits = torch.squeeze(sigmoid(score)).detach().cpu().numpy() # 예측 확률\n",
        "            label_ids = label.to('cpu').numpy() # 참 값 \n",
        "\n",
        "            y_label = y_label + label_ids.flatten().tolist()\n",
        "            y_pred = y_pred + logits.flatten().tolist() \n",
        "\n",
        "    # 예측 값 \n",
        "    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)]) \n",
        "\n",
        "    # model evaluation\n",
        "    auc, auprc, f1, lloss = get_metrics(y_label, y_pred)\n",
        "\n",
        "    lst = [\"epoch \" + str(epoch)] + list(map(float2str,[auc, auprc, f1]))\n",
        "    valid_metric_record.append(lst)\n",
        "\n",
        "    if auc > max_auc:\n",
        "        # 이전 epoch 보다 AUC 좋아지면 model_max, max_auc 갱신\n",
        "        model_max = copy.deepcopy(model)\n",
        "        max_auc = auc   \n",
        "\n",
        "    print('Validation at Epoch '+ str(epoch + 1) + ', AUROC: ' + str(auc)[:7] + \\\n",
        "            ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + \\\n",
        "            str(lloss)[:7])\n",
        "    \n",
        "    \n",
        "    table.add_row(lst)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua-OmeDU08x2"
      },
      "source": [
        "# 모델 테스트 (Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tJwvINQNq53"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "y_pred = []\n",
        "y_label = []\n",
        "y_outputs = []\n",
        "\n",
        "for i, (v_d, v_p, label) in enumerate(test_generator):\n",
        "    v_p = v_p.float().to(device) \n",
        "    v_d = v_d.float().to(device) \n",
        "    \n",
        "    # 순전파(forward-pass)\n",
        "    score = model(v_d, v_p) \n",
        "    logits = torch.squeeze(sigmoid(score)).detach().cpu().numpy()\n",
        "\n",
        "    label_ids = label.to('cpu').numpy()\n",
        "    y_label = y_label + label_ids.flatten().tolist()\n",
        "    y_pred = y_pred + logits.flatten().tolist()\n",
        "    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n",
        "\n",
        "    y_outputs.append(outputs)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocrk9Qdkq7wy"
      },
      "outputs": [],
      "source": [
        "# model evaluation\n",
        "auc, auprc, f1, lloss = get_metrics(y_label, y_pred)\n",
        "\n",
        "print('Test result - ' + ', AUROC: ' + str(auc)[:7] + ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + str(loss)[:7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dDMWkWJZgEF"
      },
      "source": [
        "# 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5zmCAcmsIxK"
      },
      "outputs": [],
      "source": [
        "def roc_curve(y_pred, y_label, figure_file, method_name):\n",
        "\t'''ROC 커브 그리기\n",
        "\n",
        "\tArgs:\n",
        "\t\ty_pred: 예측 확률 값이 담긴 리스트 [0,1]\n",
        "\t\ty_label: 참 값 (0/1)\n",
        "\t'''\n",
        "\n",
        "\timport matplotlib.pyplot as plt\n",
        "\tfrom sklearn.metrics import roc_curve, auc\n",
        "\tfrom sklearn.metrics import roc_auc_score\n",
        "\n",
        "\ty_label = np.array(y_label)\n",
        "\ty_pred = np.array(y_pred)\t\n",
        " \n",
        "\tfpr = dict()\n",
        "\ttpr = dict() \n",
        "\troc_auc = dict()\n",
        " \n",
        "\tfpr[0], tpr[0], _ = roc_curve(y_label, y_pred) # FPR / TPR 구하기\n",
        "\troc_auc[0] = auc(fpr[0], tpr[0]) # AUC 구하기\n",
        "\t\n",
        "\t# ROC 커브 그리기\n",
        "\tlw = 2\n",
        "\tplt.plot(fpr[0], tpr[0],\n",
        "         lw=lw, label= method_name + ' (area = %0.2f)' % roc_auc[0])\n",
        "\tplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "\tplt.xlim([0.0, 1.0])\n",
        "\tplt.ylim([0.0, 1.05])\n",
        "\tfontsize = 14\n",
        "\tplt.xlabel('False Positive Rate', fontsize = fontsize)\n",
        "\tplt.ylabel('True Positive Rate', fontsize = fontsize)\n",
        "\tplt.title('Receiver Operating Characteristic Curve')\n",
        "\tplt.legend(loc=\"lower right\")\n",
        "\tplt.savefig(figure_file)\n",
        " \n",
        "\n",
        "def prauc_curve(y_pred, y_label, figure_file, method_name):\n",
        "\t'''Precision-Recall 커브 그리기\n",
        "\t\n",
        "\tArgs:\n",
        "\t\ty_pred: 예측 확률 값이 담긴 리스트 [0,1]\n",
        "\t\ty_label: 참 값 (0/1)\n",
        "\t'''\n",
        "\timport matplotlib.pyplot as plt\n",
        "\tfrom sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\tfrom sklearn.metrics import f1_score\n",
        "\tfrom sklearn.metrics import auc\n",
        "\n",
        "\tlr_precision, lr_recall, _ = precision_recall_curve(y_label, y_pred) # precision, recall 구하기\n",
        "\t\n",
        "\t# 커브 그리기\n",
        "\tplt.plot(lr_recall, lr_precision, lw = 2, label= method_name + ' (area = %0.2f)' % average_precision_score(y_label, y_pred))\n",
        "\tfontsize = 14\n",
        "\tplt.xlabel('Recall', fontsize = fontsize)\n",
        "\tplt.ylabel('Precision', fontsize = fontsize)\n",
        "\tplt.title('Precision Recall Curve')\n",
        "\tplt.legend()\n",
        "\tplt.savefig(figure_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN-o2w8xsIzZ"
      },
      "outputs": [],
      "source": [
        "roc_curve(y_pred, y_label, \"CNN_test.png\", \"CNN_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wdAAkXgsI1y"
      },
      "outputs": [],
      "source": [
        "prauc_curve(y_pred, y_label, \"CNN_test.png\", \"CNN_test\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}